{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from config import *\n",
    "import pandas as pd\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def fetch(url, session):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.json()\n",
    "\n",
    "async def bound_fetch(sem, url, session):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        return await fetch(url, session)\n",
    "    \n",
    "def get_all_hubmap_dataset_uuids(nexus_token):\n",
    "    # Published data\n",
    "    hubmap_metadata_general_url = \"https://portal.hubmapconsortium.org/metadata/v0/datasets.tsv\"\n",
    "    df_raw = pd.read_csv(hubmap_metadata_general_url, delimiter='\\t')\n",
    "    published_dataset_uuids = df_raw['uuid'][1:].tolist()\n",
    "\n",
    "    # Unpublished data\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + nexus_token\n",
    "    }\n",
    "    params = {\n",
    "        \"format\" : \"json\",\n",
    "    }\n",
    "\n",
    "    BASE_URL = \"https://entity.api.hubmapconsortium.org/\"\n",
    "    endpoint = f\"datasets/unpublished\"\n",
    "    URL = BASE_URL + endpoint\n",
    "    resp = requests.get(URL, headers=headers, params=params)\n",
    "    \n",
    "    unpublished_dataset_uuids = [dt['uuid'] for dt in resp.json()]\n",
    "    \n",
    "    return {\n",
    "        \"published_uuids\" : published_dataset_uuids,\n",
    "        \"unpublished_uuids\" : unpublished_dataset_uuids,\n",
    "    }\n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "# Published data\n",
    "\n",
    "async def fetch_published_dataset_metadata_parallel(published_dataset_uuids, max_requests_per_sec, nexus_token):\n",
    "    tasks = []\n",
    "    sem = asyncio.Semaphore(max_requests_per_sec)\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        for uuid in published_dataset_uuids:    \n",
    "            url = f\"https://portal.hubmapconsortium.org/browse/dataset/{uuid}.json\"\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session))\n",
    "            tasks.append(task)\n",
    "            \n",
    "        responses = asyncio.gather(*tasks)\n",
    "        return await responses\n",
    "\n",
    "\n",
    "def get_published_hubmap_metadata_parallel(nexus_token, published_uuids, max_requests_per_sec):    \n",
    "    all_published_dataset_metadata = []\n",
    "    # failed_unpublished_fetches = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(published_uuids), max_requests_per_sec), desc=\"Fetching published data parallel\"):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        future = asyncio.ensure_future(fetch_published_dataset_metadata_parallel(published_uuids[i:i+max_requests_per_sec], max_requests_per_sec, nexus_token))\n",
    "        all_published_dataset_metadata += loop.run_until_complete(future)\n",
    "  \n",
    "    return all_published_dataset_metadata\n",
    "\n",
    "\n",
    "##################################################################################################################################\n",
    "##################################################################################################################################\n",
    "# Unpublished data\n",
    "\n",
    "async def fetch_unpublished_dataset_metadata_parallel(unpublished_dataset_uuids, max_requests_per_sec, nexus_token):\n",
    "    tasks = []\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + nexus_token\n",
    "    }\n",
    "    sem = asyncio.Semaphore(max_requests_per_sec)\n",
    "\n",
    "    async with ClientSession(headers=headers) as session:\n",
    "        for uuid in unpublished_dataset_uuids:    \n",
    "            url = f\"https://entity.api.hubmapconsortium.org/entities/{uuid}\"\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session))\n",
    "            tasks.append(task)\n",
    "            \n",
    "        responses = asyncio.gather(*tasks)\n",
    "        return await responses\n",
    "\n",
    "\n",
    "def get_unpublished_hubmap_metadata_parallel(nexus_token, unpublished_uuids, max_requests_per_sec):\n",
    "    all_unpublished_dataset_metadata = []\n",
    "    # failed_unpublished_fetches = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(unpublished_uuids), max_requests_per_sec), desc=\"Fetching unpublished data parallel\"):\n",
    "        loop = asyncio.get_event_loop()\n",
    "        future = asyncio.ensure_future(fetch_unpublished_dataset_metadata_parallel(unpublished_uuids[i:i+max_requests_per_sec], max_requests_per_sec, nexus_token))\n",
    "        all_unpublished_dataset_metadata += loop.run_until_complete(future)\n",
    "  \n",
    "    return all_unpublished_dataset_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_hubmap_metadata(filename, max_requests_per_sec, nexus_token):\n",
    "    dataset_uuids = get_all_hubmap_dataset_uuids(nexus_token)\n",
    "    \n",
    "    published_dataset_metadata_list   = get_published_hubmap_metadata_parallel(nexus_token, dataset_uuids[\"published_uuids\"], max_requests_per_sec)\n",
    "    unpublished_dataset_metadata_list = get_unpublished_hubmap_metadata_parallel(nexus_token, dataset_uuids[\"unpublished_uuids\"], max_requests_per_sec)\n",
    "    \n",
    "    published_dataset_metadata   = {dt['uuid'] : dt for dt in published_dataset_metadata_list} \n",
    "    unpublished_dataset_metadata = {dt['uuid'] : dt for dt in unpublished_dataset_metadata_list}\n",
    "\n",
    "    all_dataset_metadata = {\n",
    "        \"published_metadata\" : published_dataset_metadata,\n",
    "        \"unpublished_metadata\" : unpublished_dataset_metadata,\n",
    "    }\n",
    "\n",
    "    return all_dataset_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset_metadata = get_all_hubmap_metadata(configs[\"output_filename\"], configs[\"max_requests_per_sec\"], configs[\"nexus_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330\n",
      "1330\n"
     ]
    }
   ],
   "source": [
    "print(len(all_dataset_metadata['published_metadata'].keys()))\n",
    "print(len(set(all_dataset_metadata['published_metadata'].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946\n",
      "1946\n"
     ]
    }
   ],
   "source": [
    "print(len(all_dataset_metadata['unpublished_metadata'].keys()))\n",
    "print(len(set(all_dataset_metadata['unpublished_metadata'].keys())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for CTPOP Paper\n",
    "\n",
    "#### “dataset-id”: : { “dataset-data-access-level”: “”, “sample-id”: “”, “sample-category”: “”, “sample-data-access-level”: “”, “rui-location”: “”}\n",
    "\n",
    "\n",
    "### Devin's Pseudo Code\n",
    "\n",
    "##### For Private Dataset (unpublished) - Step 1 and 4\n",
    "##### For Public Dataset (published) - all steps\n",
    "\n",
    "```\n",
    "    1.\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    If dataset-id has “ancestor” attribute, find the FIRST ancestor entity in the “ancestor_id” list with:\n",
    "    “entity_type” = “Sample”\n",
    "    a “rui_location” attribute, \n",
    "\n",
    "    then return its “hubmap_id”, “rui_location”, and “sample_category” values\n",
    "\n",
    "    2.\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    If else, then find the FIRST ancestor entity in the “ancestor_id” list to have all of the following:\n",
    "    “entity_type” = “Sample”\n",
    "    “Sample_category” = “Block”\n",
    "\n",
    "    then return its “hubmap_id” and “sample_category” values\n",
    "\n",
    "    3.\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    If else, then find the LAST ancestor entity in the “ancestor_id” list to have all of the following:\n",
    "    “entity_type” = “Sample”\n",
    "    “Sample_category” DOES NOT EQUAL != “Organ”\n",
    "\n",
    "    then return its “hubmap_id” and “sample_category” values\n",
    "\n",
    "    4.\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "    Else, return NULL\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Private Datasets:\n",
    "\n",
    "unpublished_metadata = None\n",
    "with open(\"data/ctpop/hubmap_metadata_unpublished.json\", \"r\") as f:\n",
    "    unpublished_metadata = json.loads(f.read())\n",
    "\n",
    "# Public Datasets:\n",
    "\n",
    "published_metadata = None\n",
    "with open(\"data/ctpop/hubmap_metadata_published.json\", \"r\") as f:\n",
    "    published_metadata = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9442fd8dcb0040b929ef1c048bf181ef'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unpublished_metadata.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entites(uuid):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + configs['nexus_token']\n",
    "    }\n",
    "    url = f\"https://entity.api.hubmapconsortium.org/entities/{uuid}\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    return resp.json()\n",
    "\n",
    "def get_ancestors(uuid):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ' + configs['nexus_token']\n",
    "    }\n",
    "    url = f\"https://entity.api.hubmapconsortium.org/ancestors/{uuid}\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    return resp.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpublished datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating : 100%|██████████| 1952/1952 [10:06<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unpublished datasets:\n",
    "unpublished = {}\n",
    "for uuid, metadata in tqdm(unpublished_metadata.items(), desc=\"Populating : \"):\n",
    "    # print(json.dumps(metadata, indent=4))\n",
    "    hubmap_id = metadata[\"hubmap_id\"]\n",
    "    unpublished[hubmap_id] = {\n",
    "        # \"hubmap-id\" : metadata[\"hubmap_id\"],\n",
    "        \"dataset-data-access-level\" : metadata[\"data_access_level\"],\n",
    "        \"sample-id\" : \"\",\n",
    "        \"sample-category\" : \"\",\n",
    "        \"sample-data-access-level\" : \"\",\n",
    "        \"rui-location\" : \"\",\n",
    "    }\n",
    "    \n",
    "    # CASE 1: \n",
    "    if \"direct_ancestors\" in metadata:\n",
    "        ancestors = get_ancestors(uuid)\n",
    "        # print(json.dumps(ancestors, indent=4))\n",
    "        for ancestor in ancestors:\n",
    "            if (ancestor.get(\"entity_type\", \"\") == \"Sample\") and (\"rui_location\" in ancestor):\n",
    "                unpublished[hubmap_id][\"sample-id\"] = ancestor.get(\"lab_tissue_sample_id\", \"\")\n",
    "                unpublished[hubmap_id][\"sample-category\"] = ancestor.get(\"sample_category\", \"\")\n",
    "                unpublished[hubmap_id][\"sample-data-access-level\"] = ancestor.get(\"data_access_level\", \"\")\n",
    "                unpublished[hubmap_id][\"hubmap-id\"] = ancestor.get(\"hubmap_id\", \"\")\n",
    "                unpublished[hubmap_id][\"rui-location\"] = ancestor.get(\"rui_location\", \"\")\n",
    "                break\n",
    "\n",
    "    # CASE 4 - No updates.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpublished"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Published datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating : 100%|██████████| 1331/1331 [07:31<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Published datasets:\n",
    "published = {}\n",
    "\n",
    "# TODO: Fetch all the ancestors (parallel API requests) beforehand.\n",
    "\n",
    "for uuid, metadata in tqdm(published_metadata.items(), desc=\"Populating : \"):\n",
    "    # print(json.dumps(metadata, indent=4))\n",
    "    hubmap_id = metadata[\"hubmap_id\"] \n",
    "    published[hubmap_id] = {\n",
    "        # \"hubmap-id\" : metadata[\"hubmap_id\"],\n",
    "        \"dataset-data-access-level\" :  metadata[\"data_access_level\"],\n",
    "        \"sample-id\" : \"\",\n",
    "        \"sample-category\" : \"\",\n",
    "        \"sample-data-access-level\" : \"\",\n",
    "        \"rui-location\" : \"\",\n",
    "    }\n",
    "    \n",
    "    if \"ancestors\" in metadata:\n",
    "        ancestors = get_ancestors(uuid)\n",
    "        \n",
    "        condition_met = False\n",
    "        # CASE 1: \n",
    "        for ancestor in ancestors:\n",
    "            if (ancestor.get(\"entity_type\", \"\") == \"Sample\") and (\"rui_location\" in ancestor):\n",
    "                published[hubmap_id][\"sample-id\"] = ancestor.get(\"lab_tissue_sample_id\", \"\")\n",
    "                published[hubmap_id][\"sample-category\"] = ancestor.get(\"sample_category\", \"\")\n",
    "                published[hubmap_id][\"sample-data-access-level\"] = ancestor.get(\"data_access_level\", \"\")\n",
    "                published[hubmap_id][\"hubmap-id\"] = ancestor.get(\"hubmap_id\", \"\")\n",
    "                published[hubmap_id][\"rui-location\"] = ancestor.get(\"rui_location\", \"\")\n",
    "                condition_met = True\n",
    "                break\n",
    "\n",
    "        # CASE 2: \n",
    "        if not condition_met:\n",
    "            for ancestor in ancestors:\n",
    "                if (ancestor.get(\"entity_type\", \"\") == \"Sample\") and (ancestor.get(\"sample_category\", \"\").lower() == \"block\"):\n",
    "                    published[hubmap_id][\"sample-id\"] = ancestor.get(\"lab_tissue_sample_id\", \"\")\n",
    "                    published[hubmap_id][\"hubmap-id\"] = ancestor.get(\"hubmap_id\", \"\")\n",
    "                    # published[hubmap_id][\"sample-category\"] = ancestor.get(\"sample_category\", \"\")\n",
    "                    # published[hubmap_id][\"sample-data-access-level\"] = ancestor.get(\"data_access_level\", \"\")\n",
    "                    condition_met = True\n",
    "                    break\n",
    "        \n",
    "        # CASE 3:\n",
    "        if not condition_met:\n",
    "            for ancestor in ancestors[::-1]:\n",
    "                if (ancestor.get(\"entity_type\", \"\") == \"Sample\") and (ancestor.get(\"sample_category\", \"\").lower() != \"organ\"):\n",
    "                    # published[hubmap_id][\"sample-id\"] = ancestor.get(\"lab_tissue_sample_id\", \"\")\n",
    "                    published[hubmap_id][\"hubmap-id\"] = ancestor.get(\"hubmap_id\", \"\")\n",
    "                    published[hubmap_id][\"sample-category\"] = ancestor.get(\"sample_category\", \"\")\n",
    "                    # published[hubmap_id][\"sample-data-access-level\"] = ancestor.get(\"data_access_level\", \"\")\n",
    "                    condition_met = True\n",
    "                    break\n",
    "        \n",
    "        # CASE 4:\n",
    "        # Pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate JSON for the published and unpublished data for CTPOP paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/ctpop/ct_pop_unpublished.json\", \"w\") as outfile:\n",
    "    json.dump(unpublished, outfile)\n",
    "    \n",
    "with open(\"data/ctpop/ct_pop_published.json\", \"w\") as outfile:\n",
    "    json.dump(published, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d799180013054dbb0da6823dfa1325804a3e4e8d9ebafdd7f5e3fbd25ae51564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
